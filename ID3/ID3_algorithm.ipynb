{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f1d87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0870f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is:\n",
      "      Outlook Temperature Humidity    Wind Target\n",
      "0      sunny         hot     high    weak     no\n",
      "1      sunny         hot     high  strong     no\n",
      "2   overcast         hot     high    weak    yes\n",
      "3       rain        mild     high    weak    yes\n",
      "4       rain        cool   normal    weak    yes\n",
      "5       rain        cool   normal  strong     no\n",
      "6   overcast        cool   normal  strong    yes\n",
      "7      sunny        mild     high    weak     no\n",
      "8      sunny        cool   normal    weak    yes\n",
      "9       rain        mild   normal    weak    yes\n",
      "10     sunny        mild   normal  strong    yes\n",
      "11  overcast        mild     high  strong    yes\n",
      "12  overcast         hot   normal    weak    yes\n",
      "13      rain        mild     high  strong     no\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data.csv\")\n",
    "print(\"Dataset is:\\n\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611771be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Outlook Temperature Humidity    Wind Target\n",
      "0      sunny         hot     high    weak     no\n",
      "1      sunny         hot     high  strong     no\n",
      "2   overcast         hot     high    weak    yes\n",
      "3       rain        mild     high    weak    yes\n",
      "4       rain        cool   normal    weak    yes\n",
      "5       rain        cool   normal  strong     no\n",
      "6   overcast        cool   normal  strong    yes\n",
      "7      sunny        mild     high    weak     no\n",
      "8      sunny        cool   normal    weak    yes\n",
      "9       rain        mild   normal    weak    yes\n",
      "10     sunny        mild   normal  strong    yes\n",
      "11  overcast        mild     high  strong    yes\n",
      "12  overcast         hot   normal    weak    yes\n",
      "13      rain        mild     high  strong     no\n"
     ]
    }
   ],
   "source": [
    "training_data = dataset.iloc[:80].reset_index(drop=True)\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f35f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(column):\n",
    "    unique_values, unique_values_frequencies = np.unique(column, return_counts=True)\n",
    "    entropy = 0\n",
    "    for i in range(len(unique_values)):\n",
    "        frequency_ratio = unique_values_frequencies[i]/np.sum(unique_values_frequencies)\n",
    "        entropy += (-frequency_ratio)*np.log2(frequency_ratio)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ccd1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(data, features, most_freq_target_value):\n",
    "    \n",
    "    unique_target_values, unique_target_values_frequencies = np.unique(data['Target'], return_counts=True)\n",
    "    \n",
    "    #same target values -> add that Value as Leaf\n",
    "    if len(unique_target_values) <= 1:\n",
    "        return unique_target_values[0]\n",
    "    \n",
    "    #empty data -> add the Most Freq. Target Value of Training Data as Leaf\n",
    "    elif len(data) == 0:\n",
    "        return td_most_freq_target_value\n",
    "    \n",
    "    \n",
    "    #empty feature space -> add Previous Parent's Most Freq. Target Value as Leaf\n",
    "    elif len(features) == 0:\n",
    "        return most_freq_target_value\n",
    "    \n",
    "    else:\n",
    "        #default value\n",
    "        most_freq_target_value = unique_target_values[np.argmax(unique_target_values_frequencies)]\n",
    "        \n",
    "        #total data entropy\n",
    "        total_entropy = entropy(data[target])\n",
    "        \n",
    "        ig_of_features = []\n",
    "        \n",
    "        #information gain of each feature = total_entropy - weighted_entropy\n",
    "        for feature in features:\n",
    "            sub_features, sub_feature_frequencies = np.unique(dataset[feature], return_counts = True)\n",
    "            \n",
    "            weighted_entropy = 0\n",
    "            for i in range(len(sub_features)):\n",
    "                \n",
    "                #entropy of each sub feature\n",
    "                sub_feature_table = data.where(data[feature] == sub_features[i]).dropna()\n",
    "                sub_feature_entropy = entropy(sub_feature_table[target])\n",
    "                \n",
    "                sub_feature_freq_ratio = sub_feature_frequencies[i]/np.sum(sub_feature_frequencies)\n",
    "                \n",
    "                weighted_entropy += sub_feature_freq_ratio * sub_feature_entropy\n",
    "              \n",
    "            information_gain = total_entropy - weighted_entropy\n",
    "            ig_of_features.append(information_gain)\n",
    "        \n",
    "        #Max Information Gain feature is the Best Feature\n",
    "        best_feature = features[np.argmax(ig_of_features)]\n",
    "        \n",
    "        #add best feature as root of tree\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        #remove Best Feature from Feature Space\n",
    "        features = [ feature for feature in features if feature != best_feature ]\n",
    "        \n",
    "        #split dataset by Best Feature's sub features\n",
    "        for sub_feature in np.unique(data[best_feature]):\n",
    "            sub_data = data.where(data[best_feature] == sub_feature).dropna()\n",
    "            #run id3 on split dataset\n",
    "            sub_tree = ID3(sub_data, features, most_freq_target_value)\n",
    "        \n",
    "            #add subtree to tree\n",
    "            tree[best_feature][sub_feature] = sub_tree\n",
    "            \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0a03eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Outlook': {'overcast': 'yes',\n",
      "             'rain': {'Wind': {'strong': 'no', 'weak': 'yes'}},\n",
      "             'sunny': {'Humidity': {'high': 'no', 'normal': 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "features = training_data.columns[:-1]\n",
    "target = 'Target'\n",
    "\n",
    "td_unique_target_values, td_unique_target_values_frequencies = np.unique(training_data[target], return_counts=True)\n",
    "td_most_freq_target_value = td_unique_target_values[np.argmax(td_unique_target_values_frequencies)]\n",
    "most_freq_target_value = td_most_freq_target_value\n",
    "\n",
    "pprint(ID3(training_data, features, most_freq_target_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
