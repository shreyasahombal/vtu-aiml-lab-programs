{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44201b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# X -> (sleep hours, study hours)\n",
    "X = np.array(([2,9], [1,5], [3,6]))\n",
    "\n",
    "# Y -> (test score)\n",
    "Y = np.array(([92], [86], [89]))\n",
    "\n",
    "#scaling down values to keep within range 0.0 to 1.0\n",
    "X = X/np.amax(X, axis=0)\n",
    "Y = Y/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d13e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_layers_size = 2\n",
    "        self.hidden_layers_size = 3\n",
    "        self.output_layers_size = 1\n",
    "        \n",
    "        # weight1 matrix -> between input and hidden layers\n",
    "        self.w1 = np.random.randn(2,3)\n",
    "        \n",
    "        # weight2 matrix -> between hidden and output layers\n",
    "        self.w2 = np.random.randn(3,1)\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z = np.dot(X, self.w1)\n",
    "        self.z2 = 1/(1+np.exp(-self.z))\n",
    "        self.z3 = np.dot(self.z2, self.w2)\n",
    "        \n",
    "        output = 1/(1+np.exp(-self.z3))\n",
    "        return output\n",
    "    \n",
    "    def backward(self, X, Y, predicted_output):\n",
    "        self.output_error = Y - predicted_output\n",
    "        \n",
    "        # derivative\n",
    "        self.output_delta = self.output_error * (predicted_output * (1 - predicted_output))\n",
    "        \n",
    "        # contribution of hidden layers to output error\n",
    "        self.z2_error = self.output_delta.dot(self.w2.T)\n",
    "        \n",
    "        # derivative\n",
    "        self.z2_delta = self.z2_error * (self.z2 * (1 - self.z2))\n",
    "        \n",
    "        # adjust weight 1\n",
    "        self.w1 += learning_rate * X.T.dot(self.z2_delta)\n",
    "        \n",
    "        #adjust weight 2\n",
    "        self.w2 += learning_rate * self.z2.T.dot(self.output_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37141214",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4060bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.45935461]\n",
      " [0.48529078]\n",
      " [0.39695729]]\n",
      "Loss:\n",
      " 0.1985640977769523\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  1\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.46605545]\n",
      " [0.49145044]\n",
      " [0.40374327]]\n",
      "Loss:\n",
      " 0.19278001432522193\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.47267783]\n",
      " [0.49753176]\n",
      " [0.41046994]]\n",
      "Loss:\n",
      " 0.18714314204094326\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.47921939]\n",
      " [0.50353253]\n",
      " [0.41713367]]\n",
      "Loss:\n",
      " 0.18165305598194426\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.48567802]\n",
      " [0.50945085]\n",
      " [0.42373112]]\n",
      "Loss:\n",
      " 0.17630898363761702\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.49205189]\n",
      " [0.51528507]\n",
      " [0.43025927]]\n",
      "Loss:\n",
      " 0.17110983530023818\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.49833942]\n",
      " [0.52103376]\n",
      " [0.43671538]]\n",
      "Loss:\n",
      " 0.16605423379306283\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.50453928]\n",
      " [0.52669576]\n",
      " [0.44309699]]\n",
      "Loss:\n",
      " 0.16114054331702551\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.51065034]\n",
      " [0.53227012]\n",
      " [0.44940192]]\n",
      "Loss:\n",
      " 0.1563668972240521\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.51667171]\n",
      " [0.53775611]\n",
      " [0.45562823]]\n",
      "Loss:\n",
      " 0.15173122456738045\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.52260269]\n",
      " [0.54315318]\n",
      " [0.46177424]]\n",
      "Loss:\n",
      " 0.1472312753175625\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.52844277]\n",
      " [0.548461  ]\n",
      " [0.46783852]]\n",
      "Loss:\n",
      " 0.1428646441668173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.5341916 ]\n",
      " [0.55367938]\n",
      " [0.47381983]]\n",
      "Loss:\n",
      " 0.13862879287412744\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.53984901]\n",
      " [0.55880832]\n",
      " [0.47971716]]\n",
      "Loss:\n",
      " 0.1345210711290512\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.54541497]\n",
      " [0.56384795]\n",
      " [0.4855297 ]]\n",
      "Loss:\n",
      " 0.13053873593386822\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.55088958]\n",
      " [0.56879856]\n",
      " [0.49125681]]\n",
      "Loss:\n",
      " 0.12667896952167235\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.5562731 ]\n",
      " [0.57366054]\n",
      " [0.49689805]]\n",
      "Loss:\n",
      " 0.1229388958426893\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.56156586]\n",
      " [0.57843443]\n",
      " [0.50245312]]\n",
      "Loss:\n",
      " 0.11931559566276295\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.56676834]\n",
      " [0.58312085]\n",
      " [0.50792188]]\n",
      "Loss:\n",
      " 0.11580612032697297\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.57188109]\n",
      " [0.58772054]\n",
      " [0.51330433]]\n",
      "Loss:\n",
      " 0.11240750424804631\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.57690477]\n",
      " [0.5922343 ]\n",
      " [0.51860059]]\n",
      "Loss:\n",
      " 0.1091167761839308\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.58184011]\n",
      " [0.59666304]\n",
      " [0.52381092]]\n",
      "Loss:\n",
      " 0.1059309693719112\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.58668792]\n",
      " [0.60100773]\n",
      " [0.52893567]]\n",
      "Loss:\n",
      " 0.10284713058823247\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.59144907]\n",
      " [0.60526939]\n",
      " [0.5339753 ]]\n",
      "Loss:\n",
      " 0.09986232820260783\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.59612449]\n",
      " [0.6094491 ]\n",
      " [0.53893037]]\n",
      "Loss:\n",
      " 0.09697365929644468\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.60071518]\n",
      " [0.61354802]\n",
      " [0.54380151]]\n",
      "Loss:\n",
      " 0.09417825591231195\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.60522217]\n",
      " [0.6175673 ]\n",
      " [0.54858943]]\n",
      "Loss:\n",
      " 0.09147329050026888\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.60964654]\n",
      " [0.62150816]\n",
      " [0.55329491]]\n",
      "Loss:\n",
      " 0.08885598062431403\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.6139894 ]\n",
      " [0.62537185]\n",
      " [0.5579188 ]]\n",
      "Loss:\n",
      " 0.08632359298952615\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "Learning Rate:  0.1\n",
      "Input:\n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.61825189]\n",
      " [0.62915964]\n",
      " [0.56246199]]\n",
      "Loss:\n",
      " 0.08387344684754562\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "for i in range(30):\n",
    "    print(\"Epoch: \", i)\n",
    "    print(\"Learning Rate: \", learning_rate)\n",
    "    print(\"Input:\\n\", str(X))\n",
    "    print(\"Actual Output:\\n\", str(Y))\n",
    "    predicted_output = NN.forward(X)\n",
    "    print(\"Predicted Output:\\n\", predicted_output)\n",
    "    print(\"Loss:\\n\", str(np.mean(np.square(Y - predicted_output))))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    NN.backward(X, Y, predicted_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
